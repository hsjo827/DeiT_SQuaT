# CIFAR-100 Configuration for Teacher Model Training (DeiT-Small)
# Dataset: CIFAR-100 (resized to 224x224 for ImageNet pretrained fine-tuning)
# Approach: ImageNet Pretrained + Fine-tuning (10-20 epochs recommended)

# Dataset settings
dataset: 'torch/cifar100'
data_dir: './data/CIFAR100'
train_split: 'train'
val_split: 'test'
num_classes: 100

# Model settings
model: 'deit_small_distilled_patch16_224'
model_type: 'deit'
img_size: 224
pretrained: true  # Use ImageNet pretrained weights

# Training settings (Fine-tuning with small learning rate)
batch_size: 128
epochs: 20  # Fine-tuning: 10-20 epochs sufficient
opt: 'adamw'
lr: 0.0001  # Smaller LR for fine-tuning (was 0.001)
weight_decay: 0.05
sched: 'cosine'
warmup_lr: 0.00001
min_lr: 0.000001
warmup_epochs: 2  # Shorter warmup for fine-tuning

# Other settings
seed: 42
gpu_id: 0
workers: 4
pin_mem: true
prefetcher: false

